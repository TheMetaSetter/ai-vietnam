{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tiền Xử Lý Văn Bản: Khám Phá Sức Mạnh của NLTK trong Phân Loại Cảm Xúc (Sentiment Analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Động lực phát triển NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Vào đầu thế kỷ 21, nhu cầu về các công cụ hỗ trợ nghiên cứu và giảng dạy NLP ngày càng tăng. Nhận thấy điều này, Steven Bird và Edward Loper từ Đại học Pennsylvania đã phát triển NLTK vào năm 2001. Mục tiêu của họ là tạo ra một bộ công cụ dễ sử dụng, giúp sinh viên và nhà nghiên cứu tiếp cận NLP một cách trực quan và hiệu quả.\n",
    "\n",
    "    | Steven Bird | Edward Loper |\n",
    "    |---------|---------|\n",
    "    | ![Steven Bird](https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQ4Zzcdzwd4Rhw_a8Bnl6NUg1c-fxk_MKIxPQ&s) | ![Edward Loper](https://www.github.com/edloper.png) |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ra đời vào năm 2001, cho đến nay, NLTK đã trở thành một trong những thư viện NLP phổ biến nhất, được sử dụng rộng rãi trong cả học thuật và công nghiệp."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Những điểm thú vị về NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Kho ngữ liệu phong phú:** NLTK cung cấp hơn 50 kho ngữ liệu (corpora) khác nhau, giúp người dùng dễ dàng thực hiện các tác vụ NLP đa dạng.\n",
    "\n",
    "- **Tính năng đa dạng:** Thư viện hỗ trợ nhiều chức năng như phân loại (classification), tách từ (tokenization), gán nhãn từ loại (POS tagging), phân tích cú pháp (parsing) và suy luận ngữ nghĩa (semantic reasoning).\n",
    "\n",
    "- **Cộng đồng lớn mạnh:** Với sự phổ biến của mình, NLTK có một cộng đồng người dùng và nhà phát triển đông đảo, liên tục đóng góp và cải tiến thư viện.\n",
    "\n",
    "  - GitHub repository của NLTK có đến hơn 13700 sao và hơn 2900 lượt fork.\n",
    "\n",
    "  - NLTK được sử dụng ở hơn 329000 public GitHub repo.\n",
    "\n",
    "  - Vào ngày 19 tháng 8 năm 2024 (random fact: Ngày 19/8 là ngày truyền thống Công an nhân dân Việt Nam), NLTK phiên bản 3.9 được released. Thì điều này nghĩa là thư viện này vẫn đang được phát triển và có lượng người dùng bền vững.\n",
    "\n",
    "- **Tài liệu học tập:** NLTK đi kèm với nhiều tài liệu hướng dẫn và ví dụ minh họa, giúp người mới bắt đầu dễ dàng tiếp cận và học hỏi.\n",
    "\n",
    "  - [Sách Natual Language Processing with Python](https://tjzhifei.github.io/resources/NLTK.pdf)\n",
    "\n",
    "  - [Tutorial về NLTK của trang Real Python](https://realpython.com/nltk-nlp-python/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Một số ứng dụng thực tế của NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Phân tích cảm xúc:** Xác định cảm xúc trong các đoạn văn bản, như đánh giá sản phẩm hoặc phản hồi của khách hàng.\n",
    "\n",
    "- **Tóm tắt văn bản:** Tạo ra các bản tóm tắt ngắn gọn từ các tài liệu dài.\n",
    "\n",
    "- **Nhận diện thực thể:** Xác định và phân loại các thực thể như tên người, địa điểm, tổ chức trong văn bản.\n",
    "\n",
    "- Trong phần demo này, mình sẽ tập trung vào bài toán phân loại cảm xúc (sentiment analysis). Bộ dữ liệu mình sử dụng có thể tìm thấy ở link sau: [SPOT](https://github.com/EdinburghNLP/spot-data/tree/master/data)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nội dung chính"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import các thư viện cần thiết từ NLTK, scikit-learn, và numpy\n",
    "# để chuẩn bị cho bài toán phân loại.\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/conquerormikrokosmos/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/conquerormikrokosmos/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tải các tài nguyên của NLTK, bao gồm punkt tokenizer\n",
    "# và danh sácch các stop word.\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample reviews: ['The plot was engaging and kept me hooked.', 'This was an absolute waste of time.', 'Brilliantly directed with stellar performances.']\n"
     ]
    }
   ],
   "source": [
    "# Tạo một tập dữ liệu đánh giá phim để minh hoa.\n",
    "# Tập dữ liệu gồm các đánh giá tích cực và tiêu cực và cả trung tính.\n",
    "reviews = [\n",
    "    (\"The plot was engaging and kept me hooked.\", \"positive\"),\n",
    "    (\"This was an absolute waste of time.\", \"negative\"),\n",
    "    (\"Brilliantly directed with stellar performances.\", \"positive\"),\n",
    "    (\"I couldn't wait for it to be over.\", \"negative\"),\n",
    "    (\"An emotional rollercoaster, loved every moment.\", \"positive\"),\n",
    "    (\"The special effects were laughable.\", \"negative\"),\n",
    "    (\"It's decent, but not groundbreaking.\", \"neutral\"),\n",
    "    (\"I was neither impressed nor disappointed.\", \"neutral\"),\n",
    "    (\"Good for a one-time watch.\", \"neutral\"),\n",
    "    (\"An average film with some redeeming moments.\", \"neutral\"),\n",
    "    (\"Fantastic visuals and a gripping story.\", \"positive\"),\n",
    "    (\"Terribly written with bland characters.\", \"negative\"),\n",
    "    (\"The humor was spot on and refreshing.\", \"positive\"),\n",
    "    (\"This was a painful experience to sit through.\", \"negative\"),\n",
    "    (\"I would definitely watch it again!\", \"positive\"),\n",
    "    (\"The dialogue was cringe-worthy.\", \"negative\"),\n",
    "    (\"An inspiring tale, beautifully portrayed.\", \"positive\"),\n",
    "    (\"Not as bad as I expected, but still lacking.\", \"neutral\"),\n",
    "    (\"A decent effort, but it falls short in many areas.\", \"neutral\"),\n",
    "    (\"Nothing memorable, just another film.\", \"neutral\"),\n",
    "    (\"A masterclass in storytelling and cinematography.\", \"positive\"),\n",
    "    (\"The pacing was all over the place.\", \"negative\"),\n",
    "    (\"It left me in tears—in the best way possible.\", \"positive\"),\n",
    "    (\"This film was an absolute chore to get through.\", \"negative\"),\n",
    "    (\"A beautifully crafted narrative with deep meaning.\", \"positive\"),\n",
    "    (\"The jokes felt forced and unoriginal.\", \"negative\"),\n",
    "    (\"I couldn't stop laughing, it was hilarious!\", \"positive\"),\n",
    "    (\"The action sequences were poorly executed.\", \"negative\"),\n",
    "    (\"Worth watching for the soundtrack alone.\", \"positive\"),\n",
    "    (\"It was just alright, nothing extraordinary.\", \"neutral\"),\n",
    "    (\"The characters lacked depth, but the visuals were nice.\", \"neutral\"),\n",
    "    (\"A passable film for a rainy afternoon.\", \"neutral\"),\n",
    "    (\"Completely blew me away, a must-watch!\", \"positive\"),\n",
    "    (\"The cinematography was dull and uninspired.\", \"negative\"),\n",
    "    (\"A heartfelt movie with great performances.\", \"positive\"),\n",
    "    (\"I don't recommend this to anyone.\", \"negative\"),\n",
    "    (\"A groundbreaking film that sets a new standard.\", \"positive\"),\n",
    "    (\"Disappointingly predictable and cliche.\", \"negative\"),\n",
    "    (\"A captivating experience from start to finish.\", \"positive\"),\n",
    "    (\"The editing was choppy and distracting.\", \"negative\"),\n",
    "    (\"The story was unique and well-executed.\", \"positive\"),\n",
    "    (\"Mediocre at best, nothing stood out.\", \"neutral\"),\n",
    "    (\"It was neither entertaining nor thought-provoking.\", \"neutral\"),\n",
    "    (\"It had some great moments, but overall just okay.\", \"neutral\"),\n",
    "    (\"The performances saved an otherwise bland script.\", \"neutral\"),\n",
    "    (\"A triumphant blend of drama and action.\", \"positive\"),\n",
    "    (\"An underwhelming mess of a movie.\", \"negative\"),\n",
    "    (\"I loved the chemistry between the leads.\", \"positive\"),\n",
    "    (\"Poorly written with no redeeming qualities.\", \"negative\"),\n",
    "    (\"A delightful surprise, exceeded my expectations.\", \"positive\"),\n",
    "]\n",
    "\n",
    "texts, labels = zip(*reviews)\n",
    "print(\"Sample reviews:\", list(texts)[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Các bước tiền xử lý"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Mình chọn ra câu đầu tiên để thử đi qua từng bước tiền xử lý nhé."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I had mixed feelings about this film.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"I had mixed feelings about this film.\"\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'had', 'mixed', 'feelings', 'about', 'this', 'film', '.']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Trước tiên là mình cùng tokenize đoạn văn bản\n",
    "# này thành các phần nhỏ tên là \"token\" nhoé!\n",
    "tokens = word_tokenize(text)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"that'll\",\n",
       " 'why',\n",
       " 'ours',\n",
       " 'until',\n",
       " 'from',\n",
       " 'same',\n",
       " \"should've\",\n",
       " 'by',\n",
       " \"haven't\",\n",
       " 'we']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cùng quan sát một vài stop word\n",
    "# trong tiếng Anh nhé!\n",
    "stop_words = set(stopwords.words('english'))\n",
    "list(stop_words)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mixed', 'feelings', 'film', '.']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Giờ mình cùng lọc ra các từ không phải stop word\n",
    "# trong đoạn văn bản nha!\n",
    "filtered_tokens = [word.lower() for word in tokens if word.lower() not in stop_words]\n",
    "filtered_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['about', 'had', 'this']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vậy các stop word trong câu trên là gì nhỉ?\n",
    "stop_words_in_text = list(\n",
    "    stop_words.intersection(tokens)\n",
    ")\n",
    "stop_words_in_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Giờ mình sẽ \"gom\"/\"đóng gói\" các bước tiền xử lý bên trên\n",
    "# vào một cái hàm duy nhất thôi để tiện dùng lại sau này.\n",
    "def preprocess_text(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    filtered_tokens = [word.lower() for word in tokens if word.lower() not in stop_words]\n",
    "    return \" \".join(filtered_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['plot engaging kept hooked .',\n",
       " 'absolute waste time .',\n",
       " 'brilliantly directed stellar performances .']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dùng thử hàm vừa tạo\n",
    "processed_texts = [preprocess_text(text) for text in texts]\n",
    "list(processed_texts)[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Huấn luyện và dánh giá mô hình phân loại cảm xúc văn bản\n",
    "\n",
    "Trong phần demo này, ta sẽ huấn luyện và đánh giá một mô hình phân loại cảm xúc văn bản khi có tiền xử lý và khi không có tiền xử lý văn bản để quan sát hiệu quả của việc tiền xử lý văn bản. Các bạn có thể sẽ bất ngờ bởi kết quả so sánh!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Có một sự thật là các mô hình chỉ thực hiện tính toán trên các con số. Do đó, để mô hình \"học\" được cảm xúc thể hiện bởi văn bản, mô hình cần \"đọc\" được văn bản dưới dạng các con số. Bước đầu trong quá trình mà ta chuyển văn bản thành các con số như vậy được gọi là \"text vectorization\". Tại sao mình gọi đây là bước đầu? Đó là vì trong thực tế, còn một bước sau nữa tên là \"word embedding\". Nói nôm na là \"text vectorization\" là chuyển mỗi token về một số. Còn bước \"word embedding\" là dựa vào con số gắn với mỗi token để tìm một vector biểu diễn cho token đó. Điều đó nghĩa là thay vì chỉ dùng 1 con số trong không gian 1 chiều, người ta sẽ dùng một vector ở không gian nhiều chiều để biểu diễn một token trong bước \"word embedding\". Giá trị ở mỗi chiều sẽ thể hiện một khía cạnh liên quan đến ngữ nghĩa của một token.\n",
    "\n",
    "- Trong phần demo này, mình sẽ không bàn đến \"word embedding\" mà chỉ dừng lại ở \"text vectorization\" do giới hạn về mặt thời gian.\n",
    "\n",
    "![Word Embedding](https://miro.medium.com/v2/resize:fit:1200/1*sAJdxEsDjsPMioHyzlN3_A.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Thực hiện text vectorization bằng kỹ thuật TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mình cùng nhau tìm hiểu những điều cơ bản về kỹ thuật này nhé.\n",
    "- TF-IDF (Term Frequency-Inverse Document Frequency): Đây là một kỹ thuật phổ biến trong NLP để chuyển đổi văn bản thành các vector số. Nó phản ánh tầm quan trọng của một từ trong một văn bản so với toàn bộ tập văn bản.\n",
    "\n",
    "- Term Frequency (TF): Tần suất xuất hiện của một từ trong một văn bản cụ thể. Một từ xuất hiện càng nhiều, TF càng cao.\n",
    "Inverse Document Frequency (IDF): Đo lường mức độ phổ biến của một từ trong toàn bộ tập văn bản. Một từ xuất hiện trong nhiều văn bản, IDF càng thấp.\n",
    "\n",
    "- TF-IDF = TF * IDF: Kết hợp TF và IDF để đánh giá tầm quan trọng của từ trong ngữ cảnh tập văn bản. Từ có TF cao và IDF cao sẽ có TF-IDF cao.\n",
    "\n",
    "- `TfidfVectorizer`: Đây là một class trong scikit-learn giúp tự động tính toán TF-IDF cho các văn bản.\n",
    "\n",
    "![TF-IDF](https://www.researchgate.net/publication/376247075/figure/fig2/AS:11431281209841725@1701888441866/TF-IDFTerm-Frequency-Inverse-Document-Frequency.ppm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Phân loại cảm xúc bằng mô hình Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Mong muốn của ta hiện tại:** Ta đang muốn máy tính \"học\" được mối liên hệ giữa các từ trong đánh giá và cảm xúc tương ứng. Ví dụ: Các từ \"tuyệt vời\", \"ấn tượng\" có xu hướng xuất hiện trong các đánh giá tích cực, trong khi \"tệ\", \"thất vọng\" thường xuất hiện trong các đánh giá tiêu cực.\n",
    "\n",
    "- **Ý tưởng cốt lõi của Naive Bayes**:\n",
    "\n",
    "  - Giả định \"Ngây thơ\" (Naive):\n",
    "\n",
    "    - Giải thích: \"Naive Bayes dựa trên một giả định 'ngây thơ', đó là: các từ trong một đánh giá _độc lập_ với nhau. Có nghĩa là, sự xuất hiện của từ này không ảnh hưởng đến sự xuất hiện của từ khác.\"\n",
    "\n",
    "    - Ví dụ: \"Trong thực tế, điều này không hoàn toàn đúng, vì các từ thường đi liền với nhau (ví dụ trong các đánh giá phim thực tế: 'tuyệt vời' thường đi với 'phim'). Tuy nhiên, giả định 'ngây thơ' này lại giúp chúng ta đơn giản hóa bài toán rất nhiều mà vẫn cho kết quả tốt.\"\n",
    "\n",
    "  - Xác Suất (Probability):\n",
    "\n",
    "    - Giải thích: \"Naive Bayes hoạt động bằng cách tính toán xác suất. Chúng ta muốn biết xác suất để một đánh giá thuộc về nhãn 'tích cực' nếu trong đó có những từ như 'tuyệt vời', 'ấn tượng', v.v... và tương tự cho các nhãn 'tiêu cực' và 'trung tính'.\"\n",
    "\n",
    "    - Ví dụ: \"Giống như chúng ta đang tính xem khả năng một người thích món ăn này, dựa vào các thành phần của món ăn đó.\"\n",
    "\n",
    "  - Định Lý Bayes (Bayes' Theorem):\n",
    "\n",
    "    - Giải thích: \"Để tính toán các xác suất trên, chúng ta dùng một công thức gọi là định lý Bayes. Định lý này giúp chúng ta tính xác suất của một sự kiện (ví dụ: đánh giá là tích cực) dựa trên bằng chứng đã biết (ví dụ: các từ trong đánh giá).\"\n",
    "  \n",
    "    ![Naive Bayes Classifier](https://mlarchive.com/wp-content/uploads/2023/02/Implementing-Naive-Bayes-Classification-using-Python-1-1-1024x562-1024x585.png)\n",
    "\n",
    "    - Diễn giải: \"Công thức này có nghĩa là: xác suất đánh giá thuộc nhãn 'tích cực' (A) khi biết nó có những từ nhất định (B) bằng với xác suất có những từ đó (B) trong đánh giá 'tích cực' (A) nhân với xác suất đánh giá là 'tích cực' (A), chia cho xác suất có những từ đó (B). \" (Chúng ta dùng cách diễn giải này để đơn giản hóa công thức)\n",
    "\n",
    "- Multinomial Naive Bayes (Ứng dụng cho văn bản):\n",
    "\n",
    "  - Multinomial:\n",
    "\n",
    "    - Giải thích: \"Multinomial có nghĩa là chúng ta coi mỗi văn bản như một túi từ (bag of words), chỉ quan tâm đến tần suất xuất hiện của mỗi từ mà không quan tâm đến thứ tự của chúng.\"\n",
    "\n",
    "    - Ví dụ: \"Ví dụ, các đánh giá 'Phim rất hay' và 'Rất hay phim' sẽ được coi như nhau.\"\n",
    "\n",
    "    - Ứng Dụng:\n",
    "\n",
    "      - Giải thích: \"Multinomial Naive Bayes rất phù hợp cho các bài toán phân loại văn bản vì chúng ta thường quan tâm đến tần suất xuất hiện của từ hơn là thứ tự của chúng.\"\n",
    "\n",
    "  - Quá Trình Huấn Luyện (Training):\n",
    "\n",
    "    - Xác Suất:\n",
    "\n",
    "      - Giải thích: \"Trong quá trình huấn luyện, mô hình sẽ 'học' được xác suất các từ xuất hiện trong mỗi nhãn (ví dụ, xác suất từ 'tuyệt vời' xuất hiện trong đánh giá 'tích cực').\"\n",
    "\n",
    "      - Ví dụ: \"Mô hình sẽ 'học' được rằng từ 'tuyệt vời' có khả năng xuất hiện trong đánh giá 'tích cực' cao hơn so với đánh giá 'tiêu cực'.\"\n",
    "\n",
    "    - Đếm Tần Suất:\n",
    "\n",
    "      - Giải thích: \"Về cơ bản, mô hình chỉ cần đếm tần suất các từ trong mỗi loại đánh giá và tính toán xác suất dựa trên đó.\"\n",
    "\n",
    "  - Quá Trình Dự Đoán (Prediction):\n",
    "\n",
    "    - Tính Toán Xác Suất:\n",
    "\n",
    "      - Giải thích: \"Khi có một đánh giá mới, mô hình sẽ tính toán xác suất để đánh giá đó thuộc về từng nhãn (tích cực, tiêu cực, trung tính) dựa trên các từ trong đánh giá đó.\"\n",
    "\n",
    "      - Ví dụ: \"Mô hình sẽ tính xác suất để đánh giá 'Phim này khá ổn' thuộc về 'tích cực', 'tiêu cực', hoặc 'trung tính'.\"\n",
    "\n",
    "    - Chọn Nhãn Có Xác Suất Cao Nhất:\n",
    "\n",
    "      - Giải thích: \"Cuối cùng, mô hình sẽ chọn nhãn có xác suất cao nhất là nhãn dự đoán cho đánh giá đó.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      0.25      0.33         4\n",
      "     neutral       1.00      0.33      0.50         3\n",
      "    positive       0.29      0.67      0.40         3\n",
      "\n",
      "    accuracy                           0.40        10\n",
      "   macro avg       0.60      0.42      0.41        10\n",
      "weighted avg       0.59      0.40      0.40        10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(processed_texts)\n",
    "y = np.array(labels)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy without tokenization: 0.4\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      0.25      0.33         4\n",
      "     neutral       1.00      0.33      0.50         3\n",
      "    positive       0.29      0.67      0.40         3\n",
      "\n",
      "    accuracy                           0.40        10\n",
      "   macro avg       0.60      0.42      0.41        10\n",
      "weighted avg       0.59      0.40      0.40        10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vectorizer_raw = TfidfVectorizer()\n",
    "X_raw = vectorizer_raw.fit_transform(texts)\n",
    "X_train_raw, X_test_raw, y_train_raw, y_test_raw = train_test_split(X_raw, y, test_size=0.2, random_state=42)\n",
    "model_raw = MultinomialNB()\n",
    "model_raw.fit(X_train_raw, y_train_raw)\n",
    "y_pred_raw = model_raw.predict(X_test_raw)\n",
    "accuracy_raw = accuracy_score(y_test_raw, y_pred_raw)\n",
    "print(\"Accuracy without tokenization:\", accuracy_raw)\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Có thể thấy accuracy của 2 cách làm không khác nhau. Vậy việc tokenize có nghĩa lý gì?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.  **Nhắc lại về kết quả:**\n",
    "    *   \"Đúng là như các bạn thấy, trong trường hợp này, độ chính xác (accuracy) của mô hình khi có và không có tokenization gần như không khác biệt, cùng là 0.4. Điều này có vẻ hơi lạ, vì chúng ta đã bỏ rất nhiều công sức vào việc tokenization và loại bỏ stop words.\"\n",
    "\n",
    "2.  **Giải thích lý do accuracy không đổi (và các vấn đề có thể xảy ra):**\n",
    "    *   **Dữ liệu nhỏ:** \"Đầu tiên, chúng ta cần nhớ rằng, dữ liệu của chúng ta đang sử dụng khá nhỏ (chỉ có 50 đánh giá). Trong trường hợp dữ liệu nhỏ, các yếu tố ngẫu nhiên có thể ảnh hưởng lớn đến kết quả. Vì vậy, kết quả này chưa đủ tin cậy để đưa ra kết luận cuối cùng.\"\n",
    "    *   **TF-IDF:** \"Trong trường hợp này chúng ta đang dùng TF-IDF. TF-IDF tự bản thân nó đã \"tạo ra\" các token, vậy nên dù dữ liệu đầu vào đã được tokenize hay chưa, nó cũng sẽ tạo ra các token giống nhau. Vậy nên kết quả không có sự khác biệt. Tuy nhiên, điều này không có nghĩa là tiền xử lý văn bản không quan trọng!\"\n",
    "    *   **Mô hình Naive Bayes đơn giản:** \"Mô hình Multinomial Naive Bayes chúng ta đang sử dụng là một mô hình khá đơn giản. Trong trường hợp dữ liệu không quá phức tạp, hoặc khi các đặc trưng (features) quan trọng không bị thay đổi nhiều, mô hình đơn giản này có thể đưa ra kết quả tương tự nhau.\"\n",
    "    *   **Lỗi đánh giá:** \"Có thể thấy là dù không có sự khác biệt, nhưng cả 2 mô hình đều có kết quả khá thấp (0.4) điều này cho thấy là dữ liệu chúng ta đang sử dụng khá phức tạp hoặc mô hình chưa được điều chỉnh tốt.\"\n",
    "    *   **Stop Word:** \"Việc loại bỏ Stop Words không phải lúc nào cũng cải thiện hiệu suất. Trong một số trường hợp, Stop Word vẫn có thể chứa một số thông tin quan trọng.\"\n",
    "\n",
    "3.  **Nhấn mạnh tầm quan trọng của tiền xử lý (Tokenization vẫn có giá trị):**\n",
    "    *   **Dữ liệu lớn và phức tạp:** \"Tuy nhiên, trong thực tế, khi làm việc với các tập dữ liệu lớn và phức tạp hơn, việc tiền xử lý văn bản trở nên vô cùng quan trọng. Tokenization giúp chúng ta chia văn bản thành các đơn vị nhỏ hơn, từ đó máy tính có thể 'hiểu' được văn bản.\"\n",
    "    *   **Ngăn chặn nhiễu:** \"Tiền xử lý, bao gồm cả tokenization, giúp loại bỏ các yếu tố nhiễu (noise), như dấu câu, ký tự đặc biệt, và cả stop words (trong nhiều trường hợp), từ đó làm cho mô hình có thể tập trung vào các từ quan trọng hơn.\"\n",
    "    *  **Các thuật toán nâng cao:** \"Các thuật toán xử lý văn bản nâng cao cũng thường cần đến bước tiền xử lý để hoạt động hiệu quả. Các thuật toán Word Embedding (ví dụ Word2Vec, GloVe, FastText) cần text đã được tokenize để học từ vựng và ngữ nghĩa. Các mô hình Deep Learning cũng cần text được tokenize để có thể xử lý.\"\n",
    "    *   **Tính linh hoạt:** \"Việc tokenize giúp chúng ta có thể dễ dàng tùy chỉnh quy trình tiền xử lý cho phù hợp với từng bài toán cụ thể. Chúng ta có thể sử dụng các tokenizer khác nhau (ví dụ: tokenizer theo ký tự, theo subword), hoặc điều chỉnh cách xử lý dấu câu, số, v.v...\"\n",
    "\n",
    "4.  **Thực tế khác biệt:**\n",
    "\n",
    "    *   **Ví dụ:** \"Mình có thể lấy một ví dụ như, nếu chúng ta chỉ coi text như một mảng các ký tự, các từ như 'movie' và 'movies' sẽ được coi như 2 token khác nhau, và máy tính không thể học được mối quan hệ giữa 2 từ này. Nhưng nếu có tokenization, máy tính có thể xử lý chúng cùng một lúc hoặc chúng ta có thể áp dụng thêm các bước tiền xử lý khác như stemming, lemmatization để gom chúng về một dạng.\"\n",
    "\n",
    "5.  **Kết luận:**\n",
    "    *   \"Như vậy, dù trong trường hợp này, tokenization không tạo ra sự khác biệt rõ rệt về accuracy, nhưng nó vẫn là một bước quan trọng trong tiền xử lý văn bản, và cần thiết cho các bài toán thực tế. Nó không chỉ giúp chúng ta làm sạch dữ liệu, mà còn giúp chúng ta linh hoạt hơn trong việc tùy chỉnh các phương pháp tiền xử lý.\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
